{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNvBw9UQzpTkDVLMemAlfAD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import gensim.downloader as api\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","\n","df = pd.read_csv(\"spam.csv\", encoding='latin-1')[['v1', 'v2']]\n","df.columns = ['Label', 'Message']\n","df['Label'] = df['Label'].map({'spam': 1, 'ham': 0})\n","\n","stop_words = set(stopwords.words('english'))\n","\n","def preprocess(text):\n","    tokens = word_tokenize(text.lower())\n","    return [word for word in tokens if word.isalpha() and word not in stop_words]\n","\n","print(\"Loading Word2Vec model (this may take time)...\")\n","w2v_model = api.load(\"word2vec-google-news-300\")\n","\n","def vectorize_message(message, model):\n","    words = preprocess(message)\n","    vectors = [model[word] for word in words if word in model]\n","    if vectors:\n","        return np.mean(vectors, axis=0)\n","    else:\n","        return np.zeros(model.vector_size)\n","\n","X_vectors = np.array([vectorize_message(msg, w2v_model) for msg in df['Message']])\n","y = df['Label'].values\n","\n","X_train, X_test, y_train, y_test = train_test_split(X_vectors, y, test_size=0.2, random_state=42)\n","\n","clf = LogisticRegression(max_iter=1000)\n","clf.fit(X_train, y_train)\n","\n","y_pred = clf.predict(X_test)\n","print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n","\n","def predict_message_class(model, w2v_model, message):\n","    vec = vectorize_message(message, w2v_model).reshape(1, -1)\n","    pred = model.predict(vec)[0]\n","    return \"spam\" if pred == 1 else \"ham\"\n","\n","# Example:\n","sample = \"You won a free ticket! Reply now!\"\n","print(\"Predicted Class:\", predict_message_class(clf, w2v_model, sample))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"orV2gCwJjguk","executionInfo":{"status":"ok","timestamp":1750780265438,"user_tz":-330,"elapsed":69891,"user":{"displayName":"Jishnu Chandra Arepalli","userId":"08297995696262890689"}},"outputId":"4b020dae-cc5b-4fdf-c1cd-482a8cf7f481"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Loading Word2Vec model (this may take time)...\n","Test Accuracy: 0.9417040358744395\n","Predicted Class: spam\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"gh_qth41obFL"},"execution_count":null,"outputs":[]}]}