{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN6miEFgfG46k86odqS8s5j"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import re\n","import string\n","import nltk\n","import gensim.downloader as gensim_api\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from contractions import fix as expand_contractions\n","\n","nltk.download(\"punkt\")|\n","nltk.download(\"stopwords\")\n","nltk.download(\"wordnet\")\n","nltk.download(\"omw-1.4\")\n","\n","data = pd.read_csv(\"Tweets.csv\")[[\"airline_sentiment\", \"text\"]].dropna()\n","\n","stopword_set = set(stopwords.words(\"english\"))\n","lemmatize = WordNetLemmatizer()\n","\n","def clean_text(raw_text):\n","    raw_text = raw_text.lower()\n","    raw_text = re.sub(r\"http\\S+|www.\\S+\", \"\", raw_text)\n","    raw_text = re.sub(r\"@\\w+\", \"\", raw_text)\n","    raw_text = re.sub(r\"#\", \"\", raw_text)\n","    raw_text = re.sub(r\"[^\\w\\s]\", \"\", raw_text)\n","    raw_text = expand_contractions(raw_text)\n","    tokens = word_tokenize(raw_text)\n","    final_words = [lemmatize.lemmatize(token) for token in tokens if token.isalpha() and token not in stopword_set]\n","    return final_words\n","\n","print(\"Fetching pre-trained Google News Word2Vec model...\")\n","word2vec = gensim_api.load(\"word2vec-google-news-300\")\n","\n","def tweet_to_vector(tweet, embedding_model):\n","    words = clean_text(tweet)\n","    vectors = [embedding_model[word] for word in words if word in embedding_model]\n","    return np.mean(vectors, axis=0) if vectors else np.zeros(embedding_model.vector_size)\n","\n","X_features = np.array([tweet_to_vector(tweet, word2vec) for tweet in data[\"text\"]])\n","y_labels = data[\"airline_sentiment\"].values\n","\n","X_train, X_val, y_train, y_val = train_test_split(X_features, y_labels, test_size=0.2, stratify=y_labels, random_state=42)\n","\n","classifier = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", max_iter=1000)\n","classifier.fit(X_train, y_train)\n","\n","predictions = classifier.predict(X_val)\n","print(\"Test Set Accuracy:\", accuracy_score(y_val, predictions))\n","\n","def get_sentiment(trained_model, vector_model, tweet_text):\n","    vector_input = tweet_to_vector(tweet_text, vector_model).reshape(1, -1)\n","    return trained_model.predict(vector_input)[0]\n","\n","sample = \"I love how quickly Delta rebooked my cancelled flight!\"\n","print(\"Predicted Sentiment:\", get_sentiment(classifier, word2vec, sample))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s9SDQ9aV2tc4","executionInfo":{"status":"ok","timestamp":1750784155236,"user_tz":-330,"elapsed":81370,"user":{"displayName":"Jishnu Chandra Arepalli","userId":"08297995696262890689"}},"outputId":"95d7c6be-c7a6-4a08-e20a-7964027ffa6f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Fetching pre-trained Google News Word2Vec model...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Test Set Accuracy: 0.7687841530054644\n","Predicted Sentiment: positive\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"XPJ9KpPo3NOI"},"execution_count":null,"outputs":[]}]}